{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a46a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea4bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kma =Kkma(max_heap_size=1024*6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3bcc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/snoo/dataset/train.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(train, test_size=0.25, stratify = train.target,random_state=42) \n",
    "# 전처리 과정에서 데이터가 뒤섞이지 않도록 인덱스를 초기화\n",
    "train_data = train_data.reset_index().drop('index', axis=1)\n",
    "val_data = val_data.reset_index().drop('index', axis=1)\n",
    "# training 데이터에서 변수 추출\n",
    "train_X = train_data.reviews\n",
    "train_y = train_data.target \n",
    "\n",
    "# validation 데이터에서 변수 추출\n",
    "val_X = val_data.reviews \n",
    "val_y = val_data.target \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d1473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750,)\n",
      "(6250,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(val_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a128ba5",
   "metadata": {},
   "source": [
    "## 문장의 공백 제거 \n",
    "- 최대한 활용하기 위함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d80136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.str.replace(' ','')\n",
    "val_X = val_X.str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d077705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          마음에듭니다.자주이용할께요~\n",
       "1                           어머니다용도가방으로사드렸습니다.현재까진매우만족입니다!!\n",
       "2                                           빨아놔써쇼색상이너무이쁘네요\n",
       "3                                               향이좋아요맘에들어요\n",
       "4                                                편해서좋으네요^^\n",
       "                               ...                        \n",
       "18745    재구매두번째구매인데맛도없고안달아요전혀...배송은일주일넘게똑같이걸렸는데처음시켰던건알도...\n",
       "18746                                    너무낮아서밑에곁대어서쓰고있습니다\n",
       "18747        늘쓰던거에요.근데리뉴얼이된건지..좀두툼해진거같더라구요.아닌가..아무튼더마음에드네요\n",
       "18748                          향이너무독하고배송도느렸어요ㅠㅠ가격은저렴한것같습니다\n",
       "18749    생각했던거보단별로였던거같아요.사이즈는제가안재고사서...생각보다많이작다는느낌을받았고두...\n",
       "Name: reviews, Length: 18750, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f94763",
   "metadata": {},
   "source": [
    "## 정규표현식 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7f3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_regular_expression(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ 가-힣]')\n",
    "    result = hangul.sub('',text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b6f27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.map(apply_regular_expression)\n",
    "val_X = val_X.map(apply_regular_expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52166a4e",
   "metadata": {},
   "source": [
    "## 한국어 특성상 뒤에 느낌을 표현하는 경우가 많음\n",
    "- 뒤에서 15글자, 15글자로 한정한 이유 = Kkma 는 JVM 기반 자바모듈인데 자바의 heap에 계속 쌓이면서 문장의 길이가 길면 out of memory error 를 발생시킨다. 나는 heap사이즈를 강제로 키워도 보았지만 15글자 이상에서는 메모리 문제가 발생했다. 그래서 모든 문장을 15글자로 제한을 두었기 때문에 필요한 단어만 찾을 필요가 있었다. 앞에서 중간에서 가장 마지막에서 등등.. 한국어 문장 특성상 대부분이 두괄식 표현보다는 끝에 자기의 감정을 적는 경우가 많았다. 그래서 뒤에서 15글자로 제한을 두었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20fa712",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_short = []\n",
    "for i in range(len(train_X)):\n",
    "    train_short.append(train_X[i][-15:])\n",
    "train_short = pd.Series(train_short)\n",
    "\n",
    "val_short = []\n",
    "for i in range(len(val_X)):\n",
    "    val_short.append(val_X[i][-15:])\n",
    "val_short = pd.Series(val_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "480962fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    b = ''\n",
    "    nouns = kma.pos(text) \n",
    "    for i in range(len(nouns)):\n",
    "        if 'NNG' in nouns[i]:\n",
    "            b += nouns[i][0]+','\n",
    "        elif 'XR' in nouns[i]:\n",
    "            b += nouns[i][0]+','\n",
    "        elif 'VA' in nouns[i]:\n",
    "            if nouns[i-1][0] == '안':\n",
    "                b += '안' + nouns[i][0]+'다'+','\n",
    "            else:\n",
    "                b += nouns[i][0]+'다'+','\n",
    "        elif 'VV' in nouns[i]:\n",
    "                b += nouns[i][0]+'다'+','\n",
    "        else:\n",
    "            pass\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a955f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train_short.map(text_cleaning)\n",
    "val_clean = val_short.map(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffc0833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list(map(lambda x:x.split(',')[:-1],train_clean))\n",
    "val_list = list(map(lambda x : x.split(',')[:-1],val_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ec6ee",
   "metadata": {},
   "source": [
    "## 한글자제거 (한글자는 불필요한 단어) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32378b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmone = [] \n",
    "for x in train_list:\n",
    "    abcd = []\n",
    "    for i in x:\n",
    "        if len(i) >1 :\n",
    "            abcd.append(i)\n",
    "    train_rmone.append(abcd)\n",
    "val_rmone = []\n",
    "for x in val_list:\n",
    "    abcd = []\n",
    "    for i in x:\n",
    "        if len(i) > 1 :\n",
    "            abcd.append(i)\n",
    "    val_rmone.append(abcd)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d9989",
   "metadata": {},
   "source": [
    "## stopword (불용어 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d372b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf5e5ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmstop = []\n",
    "for x in train_rmone:\n",
    "    abcd = []\n",
    "    for i in x:\n",
    "        if i not in stopwords:\n",
    "            abcd.append(i)\n",
    "    train_rmstop.append(abcd)\n",
    "val_rmstop = []\n",
    "for x in val_rmone:\n",
    "    abcd = []\n",
    "    for i in x:\n",
    "        if i not in stopwords:\n",
    "            abcd.append(i)\n",
    "    val_rmstop.append(abcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dddb493",
   "metadata": {},
   "source": [
    "## word 2 vec 학습 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d14a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences = train_rmstop, # 학습\n",
    "                 vector_size=100,      # 임베딩된 벡터 차원 \n",
    "                 window=10,             # 컨텍스트 윈도우 크기\n",
    "                 min_count=1,          # 최소 빈도수 제한 1번 밑으로는 학습 X\n",
    "                 workers=40,           # 학습 프로세스 수 \n",
    "                 sg=1)                 # 0= CBOW, 1= Skip-Gram\n",
    "                                       # skipgram = 중심단어로 주변단어 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d00f422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('제품', 0.9943629503250122),\n",
       " ('감사', 0.9926260113716125),\n",
       " ('만족', 0.9921118021011353),\n",
       " ('상품', 0.9896460175514221),\n",
       " ('구매', 0.9892262816429138),\n",
       " ('저렴', 0.9890817403793335),\n",
       " ('괜찮다', 0.9866791367530823),\n",
       " ('싸다', 0.9859373569488525),\n",
       " ('받다', 0.985030472278595),\n",
       " ('포장', 0.9847292304039001)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('좋다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42b2dd14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('처리', 0.998714804649353),\n",
       " ('터지다', 0.998676061630249),\n",
       " ('최악', 0.9985727071762085),\n",
       " ('참다', 0.998532772064209),\n",
       " ('바꾸다', 0.9985058307647705),\n",
       " ('뜨다', 0.9985005855560303),\n",
       " ('이렇다', 0.9984793663024902),\n",
       " ('지우다', 0.998466968536377),\n",
       " ('짜증', 0.9984647035598755),\n",
       " ('놓다', 0.9984613060951233)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('안좋다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "70d0ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words, model, num_features):\n",
    "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
    "\n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "\n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words = 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[w])\n",
    "        elif w not in index2word_set:\n",
    "            num_words = 1\n",
    "            feature_vector = np.add(feature_vector,model.wv['보통'])\n",
    "        feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector\n",
    "def get_dataset(reviews, model, num_features):\n",
    "    dataset = list()\n",
    "\n",
    "    for s in reviews:\n",
    "        dataset.append(get_features(s, model, num_features))\n",
    "\n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf69d2",
   "metadata": {},
   "source": [
    "## 문장마다 벡터값 얻기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2535635",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = get_dataset(train_rmstop,model,100)\n",
    "val_vec = get_dataset(val_rmstop,model,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a243bef",
   "metadata": {},
   "source": [
    "## Logistic Regression 모델로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50167639",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf =LogisticRegression(max_iter=10000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5d5604f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(train_vec,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7491479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr_clf.predict(val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8a83327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54416"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred == val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c5c04",
   "metadata": {},
   "source": [
    "## 랜덤포레스트와 그라디언트부스팅기법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f3a29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b43f7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=107,random_state=0,\n",
    "                                n_jobs=-1,criterion='gini',\n",
    "                                max_depth=14,min_samples_leaf=11\n",
    "                               )\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc5464b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=14, min_samples_leaf=11, n_estimators=107,\n",
       "                       n_jobs=-1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=14, min_samples_leaf=11, n_estimators=107,\n",
       "                       n_jobs=-1, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=14, min_samples_leaf=11, n_estimators=107,\n",
       "                       n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(train_vec,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec937b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_clf.predict(val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "847ea11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53136"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rf_pred==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fab52012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(train_vec,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72823039",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pred = gb_clf.predict(val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1955e049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52448"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gb_pred==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e7b87",
   "metadata": {},
   "source": [
    "# 결론\n",
    "- 생각만큼 좋은 수치가 나오지 않았다. word2vec의 학습에서 최대한 활용할 수 있을 언어만 뽑아왔다고 생각했다. 문장의 처음과 끝을 다 해석했다면 다르겠지만 자바 메모리 오류로 그렇게 하지 못한건 아쉬움이다. \n",
    "- 최대한 성능을 업그레이드해보려고 노력했다. 여기서는 이정도로 적어 놓겠지만 사실 더 많은 시도를 해보았다.adaboost기법도 파이프라인을 적용해 원핫인코딩으로도 하지만 모두 성능이 좋지 않았다. 그 뜻은 word2vec 이전에 단어 뽑는 부분이 문제가 있다고 생각이 든다. \n",
    "- 다음 행선지는 카카오의 KoGPT 를 사용해보려고한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3c9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
